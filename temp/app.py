import streamlit as st
from dotenv import load_dotenv
from langchain_openai import OpenAIEmbeddings
from pinecone import Pinecone
from langchain_pinecone import PineconeVectorStore
from langchain_openai import ChatOpenAI
from langchain import hub
from langchain.chains import RetrievalQA
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import ChatPromptTemplate

st.set_page_config(page_title="ì†Œë“ì„¸ ì±—ë´‡", page_icon="ðŸ¤–")

st.title("ðŸ“Š Streamlit ê¸°ë³¸ ì˜ˆì œ")
st.caption("ì†Œë“ì„¸ì— ê´€ë ¨ë˜ ëª¨ë“ ê²ƒì„ ë‹µë³€í•´ ë“œë¦½ë‹ˆë‹¤.")
load_dotenv()

if "message_list" not in st.session_state:
  st.session_state.message_list = []

for message in st.session_state.message_list:
  with st.chat_message(message["role"]):
    st.write(message["content"])
    
def get_ai_message(user_message):  #===> ì¶”ê°€ ë¶€ë¶„
 
  embedding = OpenAIEmbeddings(model='text-embedding-3-large')
  index_name = 'tax-index'
  database = PineconeVectorStore.from_existing_index(index_name=index_name, 
                                                     embedding=embedding)

  llm = ChatOpenAI(model='gpt-4o')
  prompt = hub.pull("rlm/rag-prompt")
  retriever = database.as_retriever(search_kwargs={'k':4})

  qa_chain = RetrievalQA.from_chain_type(
      llm, 
      retriever=retriever,
      chain_type_kwargs={"prompt": prompt}
  )

  dictionary = ["ì‚¬ëžŒì„ ë‚˜íƒ€ë‚´ëŠ” í‘œí˜„ -> ê±°ì£¼ìž"]

  prompt = ChatPromptTemplate.from_template(f"""
      ì‚¬ìš©ìžì˜ ì§ˆë¬¸ì„ ë³´ê³ , ìš°ë¦¬ì˜ ì‚¬ì „ì„ ì°¸ê³ í•´ì„œ ì‚¬ìš©ìžì˜ ì§ˆë¬¸ì„ ë³€ê²½í•´ì£¼ì„¸ìš”.
      ë§Œì•½ ë³€ê²½í•  í•„ìš”ê°€ ì—†ë‹¤ê³  íŒë‹¨ëœë‹¤ë©´, ì‚¬ìš©ìžì˜ ì§ˆë¬¸ì„ ë³€ê²½í•˜ì§€ ì•Šì•„ë„ ë©ë‹ˆë‹¤.
      ê·¸ëŸ° ê²½ìš°ì—ëŠ” ì§ˆë¬¸ë§Œ ë¦¬í„´í•´ì£¼ì„¸ìš”
      ì‚¬ì „: {dictionary}
      
      ì§ˆë¬¸: {{question}}
  """)

  dictionary_chain = prompt | llm | StrOutputParser()
  tax_chain = {"query": dictionary_chain} | qa_chain
  ai_message = tax_chain.invoke({"question": user_message})
  
  return ai_message["result"]
      

if user_question := st.chat_input(placeholder="ì†Œë“ì„¸ì— ê´€ë ¨ëœ ê¶ê¸ˆí•œ ë‚´ìš©ë“¤ì„ ë§ì”€í•´ ì£¼ì„¸ìš”.!"):
  with st.chat_message("user"):
    st.write(user_question)
  st.session_state.message_list.append({"role": "user", "content": user_question})
  
  with st.spinner("ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì¤‘ìž…ë‹ˆë‹¤."):
    ai_message = get_ai_message(user_question)
    with st.chat_message("ai"):  #  ====> ì¶”ê°€ ë¶€ë¶„ë¶„
      st.write(ai_message)
    st.session_state.message_list.append({"role": "ai", "content": ai_message})
  
 